{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports Three handcrafted files, in addition to the standard numpy and matplotlib moduals.  ParticleNet.py is the neural network, which takes as input 4-vectors generated using ExpodentialDistribution.py and GaussianDistribution.py which produced 3-vector momentum and a mass vector each, where the mass vector is radomly drawn from either an expodential or a gaussian distribution respectivly.  PlotResults contains a plot function, which plots the distribution of the precentages of the Particle Neural Network's predictions for a single particle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from ExpodentialDistribution import Exp\n",
    "from GaussianDistribution import Gauss\n",
    "from ParticleNet import ParticleNet\n",
    "import numpy as np\n",
    "from PlotResults import plot\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tfv2\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.keras import layers\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "params = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the only constants needed to run this simulation thus far.  'p' the momentum is constant for all particles.  Ntrain is the number of samples the particle neural network will train on, and Ntest is the number of particles the neural network will test on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 100\n",
    "Ntrain = 5\n",
    "Ntest = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we generate our data to feed into the particle neural network.  First we create training and testing data sets from the expodential distribution modual and then the gaussian modual.  Both moduals generate a 4-vector, which includes a 3-vector momentum and a mass vector where the masses are drawn from the respective distribution at random.  Besides the 4-vector, a vector idicating that which distribution each piece of data belongs to is returned, a vector of all zeros for the expodential distribution and a vector of all ones for the gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETrain,ETrainVals = Exp(p,Ntrain)\n",
    "ETest,ETestVals = Exp(p,Ntest)\n",
    "\n",
    "GTrain,GTrainVals = Gauss(p,Ntrain)\n",
    "GTest,GTestVals = Gauss(p,Ntest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are just concatinating the data from the expodential and gaussian distributions into a single training and testing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = np.zeros((2*Ntrain,params+1))\n",
    "Test = np.zeros((2*Ntest,params+1))\n",
    "\n",
    "Train[:Ntrain,0:params] = ETrain\n",
    "Train[Ntrain:,0:params] = GTrain\n",
    "Train[:Ntrain,params] = ETrainVals\n",
    "Train[Ntrain:,params] = GTrainVals\n",
    "\n",
    "Test[:Ntest,0:params] = ETest\n",
    "Test[Ntest:,0:params] = GTest\n",
    "Test[:Ntrain,params] = ETrainVals\n",
    "Test[Ntrain:,params] = GTrainVals\n",
    "\n",
    "BUFFER_SIZE = Ntrain*2\n",
    "BATCH_SIZE = params+1\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(Train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(Test).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "Noise = np.random.uniform(0,1,[Ntrain*2,params])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "__iter__() is only supported inside of tf.function or when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ab6f9e5e2cd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2775\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2776\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n\u001b[0m\u001b[1;32m    425\u001b[0m                          \"or when eager execution is enabled.\")\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: __iter__() is only supported inside of tf.function or when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "for i in train_dataset.take(-1):\n",
    "    train = i[0:,0:params]\n",
    "    train_vals = i[0:,params]\n",
    "for i in test_dataset.take(-1):\n",
    "    test = i[0:,0:params]\n",
    "    test_vals = i[0:,params]\n",
    "train = np.array(train)\n",
    "train_vals = np.array(train_vals)\n",
    "test = np.array(test)\n",
    "test_vals = np.array(test_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(x):\n",
    "    return 10 + x*x\n",
    "\n",
    "\n",
    "def sample_data(n=10000, scale=100):\n",
    "    data = []\n",
    "\n",
    "    x = scale*(np.random.random_sample((n,))-0.5)\n",
    "\n",
    "    for i in range(n):\n",
    "        yi = get_y(x[i])\n",
    "        data.append([x[i], yi])\n",
    "\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(Z,hsize=[16, 16],reuse=False):\n",
    "    with tf.variable_scope(\"GAN/Generator\",reuse=reuse):\n",
    "        h1 = tf.layers.dense(Z,hsize[0],activation=tf.nn.leaky_relu)\n",
    "        h2 = tf.layers.dense(h1,hsize[1],activation=tf.nn.leaky_relu)\n",
    "        out = tf.layers.dense(h2,2)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(X,hsize=[16, 16],reuse=False):\n",
    "    with tf.variable_scope(\"GAN/Discriminator\",reuse=reuse):\n",
    "        h1 = tf.layers.dense(X,hsize[0],activation=tf.nn.leaky_relu)\n",
    "        h2 = tf.layers.dense(h1,hsize[1],activation=tf.nn.leaky_relu)\n",
    "        h3 = tf.layers.dense(h2,2)\n",
    "        out = tf.layers.dense(h3,1)\n",
    "\n",
    "    return out, h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,2])\n",
    "Z = tf.placeholder(tf.float32,[None,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "G_sample = generator(X)\n",
    "r_logits, r_rep = discriminator(Z)\n",
    "f_logits, g_rep = discriminator(G_sample,reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=r_logits,labels=tf.ones_like(r_logits)) + tf.nn.sigmoid_cross_entropy_with_logits(logits=f_logits,labels=tf.zeros_like(f_logits)))\n",
    "gen_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=f_logits,labels=tf.ones_like(f_logits)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/training/rmsprop.py:123: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "def loss():\n",
    "    gen_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope=\"GAN/Generator\")\n",
    "    return gen_vars\n",
    "gen_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope=\"GAN/Generator\")\n",
    "disc_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope=\"GAN/Discriminator\")\n",
    "\n",
    "\n",
    "\n",
    "gen_step = tf.train.RMSPropOptimizer(learning_rate=0.001).minimize(gen_vars[0],var_list = gen_vars) # G Train step\n",
    "disc_step = tf.train.RMSPropOptimizer(learning_rate=0.001).minimize(disc_vars[0],var_list = disc_vars) # D Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value GAN/Discriminator/dense/bias\n\t [[node GAN/Discriminator/dense/bias/read (defined at <ipython-input-8-92f6b187d5a5>:3) ]]\n\nOriginal stack trace for 'GAN/Discriminator/dense/bias/read':\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n    app.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/asyncio/events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n    self.do_execute(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2894, in run_cell\n    result = self._run_cell(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n    return runner(coro)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3165, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3357, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-29ffd176c5e1>\", line 2, in <module>\n    r_logits, r_rep = discriminator(Z)\n  File \"<ipython-input-8-92f6b187d5a5>\", line 3, in discriminator\n    h1 = tf.layers.dense(X,hsize[0],activation=tf.nn.leaky_relu)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py\", line 188, in dense\n    return layer.apply(inputs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 1722, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/base.py\", line 551, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 766, in __call__\n    self._maybe_build(inputs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 2106, in _maybe_build\n    self.build(input_shapes)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\", line 1194, in build\n    self.bias = self.add_weight(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/base.py\", line 452, in add_weight\n    variable = super(Layer, self).add_weight(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 440, in add_weight\n    variable = self._add_variable_with_custom_getter(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\", line 805, in _add_variable_with_custom_getter\n    new_variable = getter(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py\", line 1577, in get_variable\n    return get_variable_scope().get_variable(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py\", line 1320, in get_variable\n    return var_store.get_variable(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py\", line 576, in get_variable\n    return _true_getter(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py\", line 529, in _true_getter\n    return self._get_single_variable(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py\", line 950, in _get_single_variable\n    v = variables.VariableV1(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 260, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 206, in _variable_v1_call\n    return previous_getter(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 199, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py\", line 2620, in default_variable_creator\n    return variables.RefVariable(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 1656, in __init__\n    self._init_from_args(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 1861, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\", line 287, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3942, in identity\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3528, in _create_op_internal\n    ret = Operation(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 1990, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1360\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1450\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1451\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value GAN/Discriminator/dense/bias\n\t [[{{node GAN/Discriminator/dense/bias/read}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8ce63bdb3837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mZ_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_Z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdisc_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisc_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mZ_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgen_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mZ_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1369\u001b[0m                            run_metadata)\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1392\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1394\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value GAN/Discriminator/dense/bias\n\t [[node GAN/Discriminator/dense/bias/read (defined at <ipython-input-8-92f6b187d5a5>:3) ]]\n\nOriginal stack trace for 'GAN/Discriminator/dense/bias/read':\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n    app.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/asyncio/events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n    self.do_execute(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2894, in run_cell\n    result = self._run_cell(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in _run_cell\n    return runner(coro)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3165, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3357, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-29ffd176c5e1>\", line 2, in <module>\n    r_logits, r_rep = discriminator(Z)\n  File \"<ipython-input-8-92f6b187d5a5>\", line 3, in discriminator\n    h1 = tf.layers.dense(X,hsize[0],activation=tf.nn.leaky_relu)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/core.py\", line 188, in dense\n    return layer.apply(inputs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 1722, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/base.py\", line 551, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 766, in __call__\n    self._maybe_build(inputs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 2106, in _maybe_build\n    self.build(input_shapes)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\", line 1194, in build\n    self.bias = self.add_weight(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/legacy_tf_layers/base.py\", line 452, in add_weight\n    variable = super(Layer, self).add_weight(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py\", line 440, in add_weight\n    variable = self._add_variable_with_custom_getter(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\", line 805, in _add_variable_with_custom_getter\n    new_variable = getter(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py\", line 1577, in get_variable\n    return get_variable_scope().get_variable(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py\", line 1320, in get_variable\n    return var_store.get_variable(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py\", line 576, in get_variable\n    return _true_getter(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py\", line 529, in _true_getter\n    return self._get_single_variable(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py\", line 950, in _get_single_variable\n    v = variables.VariableV1(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 260, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 206, in _variable_v1_call\n    return previous_getter(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 199, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py\", line 2620, in default_variable_creator\n    return variables.RefVariable(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 264, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 1656, in __init__\n    self._init_from_args(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/variables.py\", line 1861, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\n    return target(*args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\", line 287, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3942, in identity\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 3528, in _create_op_internal\n    ret = Operation(\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 1990, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "batch_size=30\n",
    "sess = tf.Session()\n",
    "for i in range(100001):\n",
    "    X_batch = sample_data(n=batch_size)\n",
    "    Z_batch = sample_Z(batch_size, 2)\n",
    "    _, dloss = sess.run([disc_step, disc_loss], feed_dict={X: X_batch, Z: Z_batch})\n",
    "    _, gloss = sess.run([gen_step, gen_loss], feed_dict={Z: Z_batch})\n",
    "\n",
    "    print (\"Iterations: %d\\t Discriminator loss: %.4f\\t Generator loss: %.4f\"%(i,dloss,gloss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope=\"GAN/Generator\")\n",
    "print(gen_vars)\n",
    "type(gen_vars[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the particle neural network being run on the data generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b721de0f838f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParticleNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "predict = ParticleNet(train,train_vals,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we take a look at the masses for the expodential distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(x=ETrain[:,3], bins='auto')\n",
    "plt.xlabel('Masses Expodential')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Expodential Distrubution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a plot of the masses randomly generated from a Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(x=GTrain[:,3], bins='auto')\n",
    "plt.xlabel('Masses Normal')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Normal Distrubution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2, bins2, patches2 = plt.hist(x=ETrain[:,3], bins=np.arange(0,1000,5))\n",
    "n, bins, patches = plt.hist(x=GTrain[:,3], bins=np.arange(0,1000,5))\n",
    "plt.xlim(0,600)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Normal Distrubution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integN = np.sum(n2)\n",
    "integG = np.sum(n)\n",
    "print(integN)\n",
    "print(integG)\n",
    "xmin = np.argwhere(bins==25).flatten()[0]\n",
    "xmax = np.argwhere(bins==75).flatten()[0]\n",
    "ratio = np.sum(n2[xmin:xmax])/np.sum(n[xmin:xmax])\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FalseExps = sum(predict[:Ntest])/Ntest*100\n",
    "print(\"The model, on average, thought a Expodential distribution to be just that at \" + str(FalseExps[0]) + \" percent.\")\n",
    "print(\"And thought a Expodential distribution to be a Gaussian distribution at \" + str(FalseExps[1]) + \" percent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FalseGauss = (Ntest-sum(predict[Ntest:]))/Ntest*100\n",
    "print(\"The model, on average, thought a Gaussian distribution to be just that at \" + str(FalseGauss[0]) + \" percent.\")\n",
    "print(\"And thought a Gaussian distribution to be a Expodential distribution at \" + str(FalseGauss[1]) + \" percent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = Train[:,3]*predict[:,0]\n",
    "plt.hist(x=Train[:,3],weights=predict[:,1],alpha=0.5, bins=np.arange(0,1000,5))\n",
    "plt.hist(x=Train[:,3],weights=predict[:,0],alpha=0.5, bins=np.arange(0,1000,5))\n",
    "plt.xlim(0,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2, bins2, patches2 = plt.hist(x=ETrain[:,3], bins=np.arange(0,1000,5))\n",
    "n, bins, patches = plt.hist(x=GTrain[:,3], bins=np.arange(0,1000,5))\n",
    "plt.xlim(0,600)\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model(params,N):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(256, use_bias=False, input_shape=(4,1)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())    \n",
    "    \n",
    "    model.add(layers.Reshape((params, 256,1)))\n",
    "    assert model.output_shape == (None, params, 256,1)\n",
    "    \n",
    "#    for i in range(params-3):\n",
    "#        x = (params*256)/((i+1)*2)\n",
    "    model.add(layers.Conv2DTranspose(128, 1, strides=1, padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, params, 128,1)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(1, 1, strides=1, padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, params, 1, 1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = make_generator_model(params,Ntrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.uniform([params])\n",
    "generated_image = generator(noise, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_v2_behavior()\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
